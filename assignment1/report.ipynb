{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1\n",
    "## Hacettepe University Computer Science & Engineering Department\n",
    "### Course : BBM 409\n",
    "### Name : Utku İPEK\n",
    "### Student ID : 21627356\n",
    "### Instructor : Aykut ERDEM\n",
    "### TA : Burçak ASAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I: Theory Questions\n",
    "### k-Nearest Neighbor Classification\n",
    "#### 1.Assume that you have a large training dataset. Specify a disadvantage of the k- Nearest Neighbor method when using it during testing. State also your reason about your answer.\n",
    "Since k-NN is a instance based learning algorithm, it stores all the training data and that might require high amount of memory. So that prediction stage might be slow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.Create a 1-Dimensional classification dataset in which the 1-Nearest Neighbors method always gives a leave-one out cross validation error value of 1 (In other words, the method can’t guess correct class for a specific point in the dataset ). State also a proper explanation about your reasoning.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Assume that you have the following training set of positive (+), negative (-) in- stances and a single test instance (o) in the figure below (Figure 1). Assume also that the Euclidean metric is used for measuring the distance between instances. Finally consider that <img src=\"images/1.png\">\n",
    "#### • What is the class appointed to the test instance for K=1? State also reason behind your answer.\n",
    "#### • What is the class appointed to the test instance for K=3? State also reason behind your answer.\n",
    "#### • What is the class appointed to the test instance for K=5? State also reason behind your answer.\n",
    "\n",
    "For k = 1 Class appointed: '-'. Because it's nearest neighbor according to Euclidean metric is '-'.\n",
    "For k = 3 Class appointed: '-'. Because it's both nearest neighbor according to Euclidean metric is '-'.\n",
    "For k = 5 Class appointed: '+'. Because it's 2 neearest neighbors is '-' but remaining 3 is '+'. Since it is not weighted k-NN, the answer is '+'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.Fill the blanks with T (True) or F (False) for the statements below:\n",
    "#### • If all instances of the data have the same scale then k-Nearest Neighbor’s performance increases drastically. (T)\n",
    "#### • If all instances of the data have the same scale then k-Nearest Neighbor’s performance increases drastically. (T)\n",
    "#### • If all instances of the data have the same scale then k-Nearest Neighbor’s performance increases drastically. (T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Assume that you have five students have registered to a class and the class have a midterm and the final exam. You have obtained a set of their marks on two exams, which is in the table below:\n",
    "<img src=\"images/2.png\">\n",
    "#### You plan to a model which form’s is fθ(x) = θ0 + θ1x1 + θ2x2 for fitting the dataabove. The x1 shows midterm exam score while x2 shows square of the midterm score. Besides you plan to use feature scaling (using divide operation by the ”max-min”, or range, of a feature) and mean normalization. What is the normalized value of the feature x2(4)? \n",
    "<img src=\"images/3.jpeg\">"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Considering the figure below (Figure 2), which of the offsets used in linear regres- sions least square line fit? Assume that horizontal axis represents independent variable and vertical axis represents dependent variable. State your answer with your proper explanation. \n",
    "<img src=\"images/4.png\">\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.Considering the table below (Table 1), consisting of four training examples:\n",
    "<img src=\"images/5.png\">\n",
    "#### Assume that you are trying to fit the data above to the linear regression model fθ(x) = θ0 + θ1x1. Find the θ0 and θ1 values by using closed form solution (θ = (XT X)−1XT y). Also state dimension values of X, y and θ matrices. Finally show your calculations step by step.\n",
    "<img src=\"images/6.jpeg\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. State a valid reason for feature scaling and explain why it is a valid reason with respect to your reasoning.\n",
    "With feature scaling, we make sure different features on a similar scale. If we don't apply feature scaling when necessary, it takes a long time for gradient descent algorithm to find global minimum value on the cost function's contour graph. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II: Movie Reccomendation System\n",
    "### Problem \n",
    "In this assignment, we are asked to implement a movie recommendation system using k-Nearest Neighbors and weighted k-Nearest Neighbors algorithm. To implement that system, we are again asked to used user-based collaborative filtering system. We are given four datasets, and the main goal is that our program predicts the given user's rating of a given movie based on the user's k nearest neighbors and optionally it can recommend a movie list to a user again based on k nearest neighbors.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Libraries\n",
    "First, I have imported the necessary libraries. Pandas for reading and editing data, numpy for matrix operations, math for some math operations, time for calculating the time the program takes and finally matplotlib to visualise change rate of error rates due to k value.\n",
    "After that, I have read the \"movies.csv\" and \"ratings_train.csv\" files and combine them using pandas library. I have not used tags and links file, the program's train data is only contains values from ratings_train.csv\" file.\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>847434962</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1510577970</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1305696483</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1455209816</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating   timestamp             title  \\\n",
       "0       1        1     4.0   964982703  Toy Story (1995)   \n",
       "1       5        1     4.0   847434962  Toy Story (1995)   \n",
       "2      15        1     2.5  1510577970  Toy Story (1995)   \n",
       "3      17        1     4.5  1305696483  Toy Story (1995)   \n",
       "4      18        1     3.5  1455209816  Toy Story (1995)   \n",
       "\n",
       "                                        genres  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "2  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "3  Adventure|Animation|Children|Comedy|Fantasy  \n",
       "4  Adventure|Animation|Children|Comedy|Fantasy  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reading csv files using pandas library\n",
    "movies = pd.read_csv(\"movies.csv\", encoding=\"Latin1\")\n",
    "ratings = pd.read_csv(\"ratings_train.csv\", encoding=\"Latin1\")\n",
    "#combine data\n",
    "combined_ratings = pd.merge(ratings, movies, on='movieId')\n",
    "combined_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalize Rating Values\n",
    "Below, I have tried to normalize user rating values. Because, since not every user's rate scale is same each other, some prediction problems can occur and these problems may reduce the efficiency of the algorithm.\n",
    "To normalize rating values, firstly, I have calculated each user's average rating value, then found the difference between the rating value and average rating value. (Note that 'rating_y' is the average rating of the user, 'rating_avg' is the normalized rating value.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating_x</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating_y</th>\n",
       "      <th>rating_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "      <td>4.366379</td>\n",
       "      <td>-0.366379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "      <td>4.366379</td>\n",
       "      <td>-0.366379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "      <td>Heat (1995)</td>\n",
       "      <td>Action|Crime|Thriller</td>\n",
       "      <td>4.366379</td>\n",
       "      <td>-0.366379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "      <td>Seven (a.k.a. Se7en) (1995)</td>\n",
       "      <td>Mystery|Thriller</td>\n",
       "      <td>4.366379</td>\n",
       "      <td>0.633621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "      <td>Usual Suspects, The (1995)</td>\n",
       "      <td>Crime|Mystery|Thriller</td>\n",
       "      <td>4.366379</td>\n",
       "      <td>0.633621</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId  rating_x  timestamp                        title  \\\n",
       "0       1        1       4.0  964982703             Toy Story (1995)   \n",
       "1       1        3       4.0  964981247      Grumpier Old Men (1995)   \n",
       "2       1        6       4.0  964982224                  Heat (1995)   \n",
       "3       1       47       5.0  964983815  Seven (a.k.a. Se7en) (1995)   \n",
       "4       1       50       5.0  964982931   Usual Suspects, The (1995)   \n",
       "\n",
       "                                        genres  rating_y  rating_avg  \n",
       "0  Adventure|Animation|Children|Comedy|Fantasy  4.366379   -0.366379  \n",
       "1                               Comedy|Romance  4.366379   -0.366379  \n",
       "2                        Action|Crime|Thriller  4.366379   -0.366379  \n",
       "3                             Mystery|Thriller  4.366379    0.633621  \n",
       "4                       Crime|Mystery|Thriller  4.366379    0.633621  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#find average rating of users\n",
    "average_rating = pd.DataFrame(combined_ratings.groupby('userId')['rating'].mean())\n",
    "\n",
    "#normalize rating values\n",
    "final_ratings = pd.merge(combined_ratings, average_rating, on='userId')\n",
    "final_ratings['rating_avg'] = final_ratings['rating_x'] - final_ratings['rating_y']\n",
    "final_ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test Data Seperation \n",
    "I have tried to implement k-fold cross validation algorithm but I have failed. My program doesn't use k-fold cross validation. For validation, first, I have shuffled the data then split it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data \n",
    "final_ratings = final_ratings.sample(frac=1)\n",
    "msk = np.random.rand(len(final_ratings)) < 0.9\n",
    "rating_train = final_ratings[msk]\n",
    "rating_test = final_ratings[~msk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, again for the efficiency of the algorithm, I have excluded some values from the training set. My limit for a user is that a user should have rated at least 15 movies and for a movie is that a movie should have been rated at least 5 times so that when finding cosine similarity values from user-movie vectors, the values make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating_x</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "      <th>rating_y</th>\n",
       "      <th>rating_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23339</th>\n",
       "      <td>414</td>\n",
       "      <td>379</td>\n",
       "      <td>2.0</td>\n",
       "      <td>961515325</td>\n",
       "      <td>Timecop (1994)</td>\n",
       "      <td>Action|Sci-Fi|Thriller</td>\n",
       "      <td>3.391957</td>\n",
       "      <td>-1.391957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54238</th>\n",
       "      <td>284</td>\n",
       "      <td>231</td>\n",
       "      <td>4.0</td>\n",
       "      <td>832695208</td>\n",
       "      <td>Dumb &amp; Dumber (Dumb and Dumber) (1994)</td>\n",
       "      <td>Adventure|Comedy</td>\n",
       "      <td>3.715909</td>\n",
       "      <td>0.284091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38012</th>\n",
       "      <td>597</td>\n",
       "      <td>1395</td>\n",
       "      <td>4.0</td>\n",
       "      <td>940362008</td>\n",
       "      <td>Tin Men (1987)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "      <td>3.977427</td>\n",
       "      <td>0.022573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37120</th>\n",
       "      <td>587</td>\n",
       "      <td>236</td>\n",
       "      <td>5.0</td>\n",
       "      <td>953139541</td>\n",
       "      <td>French Kiss (1995)</td>\n",
       "      <td>Action|Comedy|Romance</td>\n",
       "      <td>3.975758</td>\n",
       "      <td>1.024242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14113</th>\n",
       "      <td>266</td>\n",
       "      <td>785</td>\n",
       "      <td>4.0</td>\n",
       "      <td>944940668</td>\n",
       "      <td>Kingpin (1996)</td>\n",
       "      <td>Comedy</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating_x  timestamp  \\\n",
       "23339     414      379       2.0  961515325   \n",
       "54238     284      231       4.0  832695208   \n",
       "38012     597     1395       4.0  940362008   \n",
       "37120     587      236       5.0  953139541   \n",
       "14113     266      785       4.0  944940668   \n",
       "\n",
       "                                        title                  genres  \\\n",
       "23339                          Timecop (1994)  Action|Sci-Fi|Thriller   \n",
       "54238  Dumb & Dumber (Dumb and Dumber) (1994)        Adventure|Comedy   \n",
       "38012                          Tin Men (1987)            Comedy|Drama   \n",
       "37120                      French Kiss (1995)   Action|Comedy|Romance   \n",
       "14113                          Kingpin (1996)                  Comedy   \n",
       "\n",
       "       rating_y  rating_avg  \n",
       "23339  3.391957   -1.391957  \n",
       "54238  3.715909    0.284091  \n",
       "38012  3.977427    0.022573  \n",
       "37120  3.975758    1.024242  \n",
       "14113  3.500000    0.500000  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#exclude some movies and users from training set\n",
    "count = rating_train['userId'].value_counts()\n",
    "rating_train = rating_train[rating_train['userId'].isin(count[count >= 15].index)]\n",
    "count_1 = rating_train['movieId'].value_counts()\n",
    "rating_train = rating_train[rating_train['movieId'].isin(count_1[count_1 >= 5].index)]\n",
    "rating_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After excluding the values from training set, I have created the userId-MovieId pivot table which is necessary to implement a collaborative-filtering system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>171763</th>\n",
       "      <th>174055</th>\n",
       "      <th>175303</th>\n",
       "      <th>176101</th>\n",
       "      <th>176371</th>\n",
       "      <th>177593</th>\n",
       "      <th>177765</th>\n",
       "      <th>179819</th>\n",
       "      <th>180031</th>\n",
       "      <th>187593</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.366379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.366379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.366379</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.506369</td>\n",
       "      <td>1.506369</td>\n",
       "      <td>1.506369</td>\n",
       "      <td>0.506369</td>\n",
       "      <td>0.506369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.506369</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2824 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId    1         2         3         5         6         7       9       \\\n",
       "userId                                                                        \n",
       "1       -0.366379       NaN -0.366379       NaN -0.366379       NaN     NaN   \n",
       "2             NaN       NaN       NaN       NaN       NaN       NaN     NaN   \n",
       "3             NaN       NaN       NaN       NaN       NaN       NaN     NaN   \n",
       "5        0.363636       NaN       NaN       NaN       NaN       NaN     NaN   \n",
       "6             NaN  0.506369  1.506369  1.506369  0.506369  0.506369     NaN   \n",
       "\n",
       "movieId  10        11      12      ...  171763  174055  175303  176101  \\\n",
       "userId                             ...                                   \n",
       "1           NaN       NaN     NaN  ...     NaN     NaN     NaN     NaN   \n",
       "2           NaN       NaN     NaN  ...     NaN     NaN     NaN     NaN   \n",
       "3           NaN       NaN     NaN  ...     NaN     NaN     NaN     NaN   \n",
       "5           NaN       NaN     NaN  ...     NaN     NaN     NaN     NaN   \n",
       "6           NaN  0.506369     NaN  ...     NaN     NaN     NaN     NaN   \n",
       "\n",
       "movieId  176371  177593  177765  179819  180031  187593  \n",
       "userId                                                   \n",
       "1           NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "2           NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "3           NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "5           NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "6           NaN     NaN     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[5 rows x 2824 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating pivot table with normalized rating values\n",
    "pivot = pd.pivot_table(rating_train, values='rating_avg', index='userId', columns='movieId')\n",
    "pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen above, there are too many 'nan' values in the pivot table since not every user rated every movie in the training set. From there, there are some approaches like fill the 'nan' values with zeros, or fill the 'nan' values with user's rating average. Firstly I have decided to fill the 'nan' values with zeros but then I have realized that some users' normalized rating values are already zero. And because of that while I was trying to create similarity matrix, since some vectors have all zero values, my cosine similarity function produces warnings because of zero division. Then I have decided to fill the 'nan' values with movie average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>movieId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>...</th>\n",
       "      <th>171763</th>\n",
       "      <th>174055</th>\n",
       "      <th>175303</th>\n",
       "      <th>176101</th>\n",
       "      <th>176371</th>\n",
       "      <th>177593</th>\n",
       "      <th>177765</th>\n",
       "      <th>179819</th>\n",
       "      <th>180031</th>\n",
       "      <th>187593</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.366379</td>\n",
       "      <td>-0.036708</td>\n",
       "      <td>-0.366379</td>\n",
       "      <td>-0.499152</td>\n",
       "      <td>-0.366379</td>\n",
       "      <td>-0.387433</td>\n",
       "      <td>-0.528285</td>\n",
       "      <td>-0.09539</td>\n",
       "      <td>0.096453</td>\n",
       "      <td>-1.06375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783574</td>\n",
       "      <td>0.325015</td>\n",
       "      <td>-0.14615</td>\n",
       "      <td>-0.405721</td>\n",
       "      <td>0.323041</td>\n",
       "      <td>0.966466</td>\n",
       "      <td>-0.060698</td>\n",
       "      <td>-0.13184</td>\n",
       "      <td>0.279824</td>\n",
       "      <td>0.240034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.329982</td>\n",
       "      <td>-0.036708</td>\n",
       "      <td>-0.292146</td>\n",
       "      <td>-0.499152</td>\n",
       "      <td>0.410953</td>\n",
       "      <td>-0.387433</td>\n",
       "      <td>-0.528285</td>\n",
       "      <td>-0.09539</td>\n",
       "      <td>0.096453</td>\n",
       "      <td>-1.06375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783574</td>\n",
       "      <td>0.325015</td>\n",
       "      <td>-0.14615</td>\n",
       "      <td>-0.405721</td>\n",
       "      <td>0.323041</td>\n",
       "      <td>0.966466</td>\n",
       "      <td>-0.060698</td>\n",
       "      <td>-0.13184</td>\n",
       "      <td>0.279824</td>\n",
       "      <td>0.240034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.329982</td>\n",
       "      <td>-0.036708</td>\n",
       "      <td>-0.292146</td>\n",
       "      <td>-0.499152</td>\n",
       "      <td>0.410953</td>\n",
       "      <td>-0.387433</td>\n",
       "      <td>-0.528285</td>\n",
       "      <td>-0.09539</td>\n",
       "      <td>0.096453</td>\n",
       "      <td>-1.06375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783574</td>\n",
       "      <td>0.325015</td>\n",
       "      <td>-0.14615</td>\n",
       "      <td>-0.405721</td>\n",
       "      <td>0.323041</td>\n",
       "      <td>0.966466</td>\n",
       "      <td>-0.060698</td>\n",
       "      <td>-0.13184</td>\n",
       "      <td>0.279824</td>\n",
       "      <td>0.240034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>-0.036708</td>\n",
       "      <td>-0.292146</td>\n",
       "      <td>-0.499152</td>\n",
       "      <td>0.410953</td>\n",
       "      <td>-0.387433</td>\n",
       "      <td>-0.528285</td>\n",
       "      <td>-0.09539</td>\n",
       "      <td>0.096453</td>\n",
       "      <td>-1.06375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783574</td>\n",
       "      <td>0.325015</td>\n",
       "      <td>-0.14615</td>\n",
       "      <td>-0.405721</td>\n",
       "      <td>0.323041</td>\n",
       "      <td>0.966466</td>\n",
       "      <td>-0.060698</td>\n",
       "      <td>-0.13184</td>\n",
       "      <td>0.279824</td>\n",
       "      <td>0.240034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.329982</td>\n",
       "      <td>0.506369</td>\n",
       "      <td>1.506369</td>\n",
       "      <td>1.506369</td>\n",
       "      <td>0.506369</td>\n",
       "      <td>0.506369</td>\n",
       "      <td>-0.528285</td>\n",
       "      <td>-0.09539</td>\n",
       "      <td>0.506369</td>\n",
       "      <td>-1.06375</td>\n",
       "      <td>...</td>\n",
       "      <td>0.783574</td>\n",
       "      <td>0.325015</td>\n",
       "      <td>-0.14615</td>\n",
       "      <td>-0.405721</td>\n",
       "      <td>0.323041</td>\n",
       "      <td>0.966466</td>\n",
       "      <td>-0.060698</td>\n",
       "      <td>-0.13184</td>\n",
       "      <td>0.279824</td>\n",
       "      <td>0.240034</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2824 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "movieId    1         2         3         5         6         7         9       \\\n",
       "userId                                                                          \n",
       "1       -0.366379 -0.036708 -0.366379 -0.499152 -0.366379 -0.387433 -0.528285   \n",
       "2        0.329982 -0.036708 -0.292146 -0.499152  0.410953 -0.387433 -0.528285   \n",
       "3        0.329982 -0.036708 -0.292146 -0.499152  0.410953 -0.387433 -0.528285   \n",
       "5        0.363636 -0.036708 -0.292146 -0.499152  0.410953 -0.387433 -0.528285   \n",
       "6        0.329982  0.506369  1.506369  1.506369  0.506369  0.506369 -0.528285   \n",
       "\n",
       "movieId   10        11       12      ...    171763    174055   175303  \\\n",
       "userId                               ...                                \n",
       "1       -0.09539  0.096453 -1.06375  ...  0.783574  0.325015 -0.14615   \n",
       "2       -0.09539  0.096453 -1.06375  ...  0.783574  0.325015 -0.14615   \n",
       "3       -0.09539  0.096453 -1.06375  ...  0.783574  0.325015 -0.14615   \n",
       "5       -0.09539  0.096453 -1.06375  ...  0.783574  0.325015 -0.14615   \n",
       "6       -0.09539  0.506369 -1.06375  ...  0.783574  0.325015 -0.14615   \n",
       "\n",
       "movieId    176101    176371    177593    177765   179819    180031    187593  \n",
       "userId                                                                        \n",
       "1       -0.405721  0.323041  0.966466 -0.060698 -0.13184  0.279824  0.240034  \n",
       "2       -0.405721  0.323041  0.966466 -0.060698 -0.13184  0.279824  0.240034  \n",
       "3       -0.405721  0.323041  0.966466 -0.060698 -0.13184  0.279824  0.240034  \n",
       "5       -0.405721  0.323041  0.966466 -0.060698 -0.13184  0.279824  0.240034  \n",
       "6       -0.405721  0.323041  0.966466 -0.060698 -0.13184  0.279824  0.240034  \n",
       "\n",
       "[5 rows x 2824 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fill nan's with appropriate values\n",
    "final_pivot = pivot.fillna(pivot.mean(axis=0))\n",
    "final_pivot.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions For Similarity Operations\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"images/7.png\">\n",
    "I have chosen the above similarity function. It's implementation is below. Among other two functions, while the one that is named create_vectors is takes the pivot table as a parameter and create movie rating vectors using dictionary data structure for every user and returns it, apply_similarity function creates a user-user similarity_matrix and fills the value with the similarity of the vectors that is created by the create_vectors function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cosine similarity function\n",
    "def cosine_sim(vector1, vector2):\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm_v1 = np.linalg.norm(vector1)\n",
    "    norm_v2 = np.linalg.norm(vector2)\n",
    "    similarity_value = dot_product / (norm_v1 * norm_v2)\n",
    "    return similarity_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create vectors to apply similarity function using dictionary\n",
    "def create_vectors(training_data):\n",
    "    Dict = {}\n",
    "    for i in range(len(training_data.index)):\n",
    "        Dict[training_data.index[i]] = training_data.iloc[i, :].values\n",
    "    return Dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying cosine similarity function to users\n",
    "def apply_similarity(user_vector, training_data):\n",
    "    cosine = pd.DataFrame(index=training_data.index, columns=training_data.index)\n",
    "    for key_1 in user_vector.keys():\n",
    "        for key_2 in user_vector.keys():\n",
    "            if math.isnan(cosine[key_1][key_2]):\n",
    "                if(key_1 == key_2):\n",
    "                    cosine[key_1][key_2] = 0\n",
    "                else:\n",
    "                    sim_value = cosine_sim(user_vector[key_1], user_vector[key_2])\n",
    "                    cosine[key_1][key_2] = sim_value\n",
    "                    cosine[key_2][key_1] = sim_value\n",
    "    return cosine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### k-NN and Weighted k-NN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, to find nearest neighbors of the given user, I have implemented find_nearest_neighbors function which takes five parameters and returns k nearest neighbors which is rated given movieId as a list. There is an important thing here, if the given movie is rated less than k times, the function adds other nearest neighbors which have not rated that movie.<img src=\"images/8.png\">\n",
    "\n",
    "<img src=\"images/9.png\">\n",
    "For k-NN rating prediction I have used the above formula.\n",
    "\n",
    "<img src=\"images/10.png\">\n",
    "For weighted k-NN rating prediction I have used the above formula where 's' is the similarity value. [1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find k nearest neighbors of a specified user\n",
    "def find_nearest_neighbors(k, userId, movieId, similarity_matrix, pivot):\n",
    "    neighborhood = []\n",
    "    users_seen_movie =[]\n",
    "    users_not_seen_movie = []\n",
    "    for user in pivot.index:\n",
    "        if math.isnan(pivot[movieId][user]):\n",
    "            users_not_seen_movie.append(user)\n",
    "        else:\n",
    "            users_seen_movie.append(user)\n",
    "    \n",
    "    temp = similarity_matrix.sort_values(userId, axis=1, ascending=False)\n",
    "            \n",
    "    for index in temp.columns.values:\n",
    "        if index in users_seen_movie:\n",
    "            neighborhood.append(index)\n",
    "            \n",
    "    if (len(neighborhood) <= k):\n",
    "        while (len(neighborhood) <= k):\n",
    "            for i in temp.columns.values:\n",
    "                if i in users_not_seen_movie:\n",
    "                    neighborhood.append(i) \n",
    "                \n",
    "    return neighborhood[0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rating prediction functions\n",
    "def knn_rating_predict(k, userId, movieId, similarity_matrix, pivot, final_pivot):\n",
    "    total_rating = 0;\n",
    "    rating_avg=0;\n",
    "    \n",
    "    neighborhood = find_nearest_neighbors(k, userId, movieId, similarity_matrix, pivot)\n",
    "    \n",
    "    for neighbor in neighborhood:\n",
    "            total_rating += final_pivot[movieId][neighbor]\n",
    "            \n",
    "    rating_avg = total_rating/len(neighborhood)\n",
    "    \n",
    "    return rating_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_knn_rating_predict(k, userId, movieId, similarity_matrix, pivot, final_pivot):\n",
    "    w_rating = 0\n",
    "    rating_avg = 0\n",
    "    sim_sum = 0\n",
    "    \n",
    "    neighborhood = find_nearest_neighbors(k, userId, movieId, similarity_matrix, pivot)\n",
    "    for neighbor in neighborhood:\n",
    "        sim_value = similarity_matrix[neighbor][userId]\n",
    "        w_rating += (sim_value * final_pivot[movieId][neighbor])\n",
    "        sim_sum += sim_value\n",
    "        \n",
    "    rating_avg = (w_rating / sim_sum)\n",
    "\n",
    "    return rating_avg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, there are functions to calculate Mean Absolute Error.<img src=\"images/11.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#error calculations\n",
    "def calculate_error(real_rating, predicted_rating):\n",
    "    return abs(real_rating - predicted_rating)\n",
    "\n",
    "def calculate_MAE(error_list):\n",
    "    return (sum(error_list) / len(error_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train function takes final_pivot table as a parameter returns the user-user similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(final_pivot):\n",
    "    user_vectors = create_vectors(final_pivot)\n",
    "    similarity_matrix = apply_similarity(user_vectors, final_pivot)\n",
    "    return similarity_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the test_model function, I have taken some precautions for some problems may occur. The first problem is if the train set does not contain the movie in the test set. For that I have taken the given user's rating average as a prediction. The second, if train set does not contain the user in the test set. For that as a prediction, I have taken movie rating average. The third is both of the values are missing in the training set and for that I have passed that user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(k, similarity_matrix, final_pivot, pivot, error_list, w_error_list):\n",
    "    \n",
    "    is_Contain_User = False\n",
    "    is_Contain_Movie = False\n",
    "    \n",
    "    for index in rating_test.index:\n",
    "        userId = rating_test.loc[index, 'userId']\n",
    "        movieId = rating_test.loc[index, 'movieId']\n",
    "        \n",
    "        if userId in pivot.index:\n",
    "            is_Contain_User = True\n",
    "        if movieId in pivot.columns:\n",
    "            is_Contain_Movie  = True\n",
    "            \n",
    "        if is_Contain_User == True and is_Contain_Movie == True:\n",
    "            pred_1 = knn_rating_predict(k, userId, movieId, similarity_matrix, pivot, final_pivot)\n",
    "            pred_2 = weighted_knn_rating_predict(k, userId, movieId, similarity_matrix, pivot, final_pivot)\n",
    "         \n",
    "        elif is_Contain_User == True and is_Contain_Movie == False:\n",
    "            pred_1 = pivot.loc[userId, :].mean()\n",
    "            pred_2 = pivot.loc[userId, :].mean()\n",
    "            \n",
    "        elif is_Contain_User == False and is_Contain_Movie == True:\n",
    "            pred_1 = pivot.loc[:, movieId].mean()\n",
    "            pred_2 = pivot.loc[:, movieId].mean()\n",
    "        \n",
    "        else:\n",
    "            pred_1 = False\n",
    "            pred_2 = False\n",
    "            print(\"Train set does not contain userID: \", userId, \" and movieId: \", movieId, \" for k-NN.\")\n",
    "            print(\"Train set does not contain userID: \", userId, \" and movieId: \", movieId, \" for Weighted k-NN.\")\n",
    "            \n",
    "        real_rating = rating_test.loc[index, 'rating_avg']\n",
    "        \n",
    "        error = calculate_error(real_rating, pred_1)\n",
    "        error_list.append(abs(error))\n",
    "        \n",
    "        w_error = calculate_error(real_rating, pred_2)\n",
    "        w_error_list.append(abs(w_error))\n",
    "        \n",
    "        is_Contain_User = False\n",
    "        is_Contain_Movie = False\n",
    "                    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution of the Program\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>userId</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>...</th>\n",
       "      <th>597</th>\n",
       "      <th>598</th>\n",
       "      <th>599</th>\n",
       "      <th>601</th>\n",
       "      <th>603</th>\n",
       "      <th>605</th>\n",
       "      <th>606</th>\n",
       "      <th>607</th>\n",
       "      <th>608</th>\n",
       "      <th>610</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>userId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.928085</td>\n",
       "      <td>0.881608</td>\n",
       "      <td>0.921072</td>\n",
       "      <td>0.829881</td>\n",
       "      <td>0.922833</td>\n",
       "      <td>0.92339</td>\n",
       "      <td>0.908651</td>\n",
       "      <td>0.929202</td>\n",
       "      <td>0.930552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.815448</td>\n",
       "      <td>0.91374</td>\n",
       "      <td>0.668423</td>\n",
       "      <td>0.922697</td>\n",
       "      <td>0.687499</td>\n",
       "      <td>0.871187</td>\n",
       "      <td>0.809935</td>\n",
       "      <td>0.856182</td>\n",
       "      <td>0.695668</td>\n",
       "      <td>0.799364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.928085</td>\n",
       "      <td>0</td>\n",
       "      <td>0.933674</td>\n",
       "      <td>0.974136</td>\n",
       "      <td>0.876792</td>\n",
       "      <td>0.966867</td>\n",
       "      <td>0.975444</td>\n",
       "      <td>0.96914</td>\n",
       "      <td>0.979544</td>\n",
       "      <td>0.980329</td>\n",
       "      <td>...</td>\n",
       "      <td>0.856719</td>\n",
       "      <td>0.959994</td>\n",
       "      <td>0.7114</td>\n",
       "      <td>0.973997</td>\n",
       "      <td>0.739171</td>\n",
       "      <td>0.926135</td>\n",
       "      <td>0.858247</td>\n",
       "      <td>0.899179</td>\n",
       "      <td>0.724849</td>\n",
       "      <td>0.853181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.881608</td>\n",
       "      <td>0.933674</td>\n",
       "      <td>0</td>\n",
       "      <td>0.925265</td>\n",
       "      <td>0.836527</td>\n",
       "      <td>0.919781</td>\n",
       "      <td>0.929386</td>\n",
       "      <td>0.922383</td>\n",
       "      <td>0.933305</td>\n",
       "      <td>0.934407</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809935</td>\n",
       "      <td>0.914983</td>\n",
       "      <td>0.676127</td>\n",
       "      <td>0.926952</td>\n",
       "      <td>0.709952</td>\n",
       "      <td>0.881958</td>\n",
       "      <td>0.808269</td>\n",
       "      <td>0.858528</td>\n",
       "      <td>0.688332</td>\n",
       "      <td>0.814171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.921072</td>\n",
       "      <td>0.974136</td>\n",
       "      <td>0.925265</td>\n",
       "      <td>0</td>\n",
       "      <td>0.868733</td>\n",
       "      <td>0.952764</td>\n",
       "      <td>0.966629</td>\n",
       "      <td>0.957262</td>\n",
       "      <td>0.9728</td>\n",
       "      <td>0.972422</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850422</td>\n",
       "      <td>0.951674</td>\n",
       "      <td>0.708763</td>\n",
       "      <td>0.965392</td>\n",
       "      <td>0.733442</td>\n",
       "      <td>0.913994</td>\n",
       "      <td>0.848347</td>\n",
       "      <td>0.89227</td>\n",
       "      <td>0.714817</td>\n",
       "      <td>0.841051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.829881</td>\n",
       "      <td>0.876792</td>\n",
       "      <td>0.836527</td>\n",
       "      <td>0.868733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.854525</td>\n",
       "      <td>0.874905</td>\n",
       "      <td>0.873679</td>\n",
       "      <td>0.880677</td>\n",
       "      <td>0.879281</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746917</td>\n",
       "      <td>0.861023</td>\n",
       "      <td>0.62515</td>\n",
       "      <td>0.872854</td>\n",
       "      <td>0.652756</td>\n",
       "      <td>0.834825</td>\n",
       "      <td>0.761518</td>\n",
       "      <td>0.814183</td>\n",
       "      <td>0.628871</td>\n",
       "      <td>0.763263</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 427 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "userId       1         2         3         5         6         8         9    \\\n",
       "userId                                                                         \n",
       "1              0  0.928085  0.881608  0.921072  0.829881  0.922833   0.92339   \n",
       "2       0.928085         0  0.933674  0.974136  0.876792  0.966867  0.975444   \n",
       "3       0.881608  0.933674         0  0.925265  0.836527  0.919781  0.929386   \n",
       "5       0.921072  0.974136  0.925265         0  0.868733  0.952764  0.966629   \n",
       "6       0.829881  0.876792  0.836527  0.868733         0  0.854525  0.874905   \n",
       "\n",
       "userId       11        12        13   ...       597       598       599  \\\n",
       "userId                                ...                                 \n",
       "1       0.908651  0.929202  0.930552  ...  0.815448   0.91374  0.668423   \n",
       "2        0.96914  0.979544  0.980329  ...  0.856719  0.959994    0.7114   \n",
       "3       0.922383  0.933305  0.934407  ...  0.809935  0.914983  0.676127   \n",
       "5       0.957262    0.9728  0.972422  ...  0.850422  0.951674  0.708763   \n",
       "6       0.873679  0.880677  0.879281  ...  0.746917  0.861023   0.62515   \n",
       "\n",
       "userId       601       603       605       606       607       608       610  \n",
       "userId                                                                        \n",
       "1       0.922697  0.687499  0.871187  0.809935  0.856182  0.695668  0.799364  \n",
       "2       0.973997  0.739171  0.926135  0.858247  0.899179  0.724849  0.853181  \n",
       "3       0.926952  0.709952  0.881958  0.808269  0.858528  0.688332  0.814171  \n",
       "5       0.965392  0.733442  0.913994  0.848347   0.89227  0.714817  0.841051  \n",
       "6       0.872854  0.652756  0.834825  0.761518  0.814183  0.628871  0.763263  \n",
       "\n",
       "[5 rows x 427 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training of the model and creation of the similarity matrix between users\n",
    "similarity_matrix = train_model(final_pivot)\n",
    "similarity_matrix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "698.3069543838501  seconds.\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "#two lists for error values\n",
    "all_error = []\n",
    "w_all_error = []\n",
    "errors = []\n",
    "weighted_errors = []\n",
    "\n",
    "k=5\n",
    "\n",
    "while (k != 65):\n",
    "    \n",
    "    test_model(k, similarity_matrix, final_pivot, pivot, errors, weighted_errors)\n",
    "    all_error.append(calculate_MAE(errors))\n",
    "    w_all_error.append(calculate_MAE(weighted_errors))\n",
    "\n",
    "    k = k + 15\n",
    "    \n",
    "end = time.time()\n",
    "print (end - start, \" seconds.\")\n",
    "\n",
    "\n",
    "#print(calculate_MAE(errors))\n",
    "#print(calculate_MAE(weighted_errors))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7352450824758353, 0.7219091874420986, 0.7159813731242644, 0.712558922094323]\n",
      "[0.7352487359081851, 0.721994900842194, 0.716088851478067, 0.7126753731117677]\n"
     ]
    }
   ],
   "source": [
    "print(all_error)\n",
    "print(w_all_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choosing Appropriate 'k' value\n",
    "As seen above, there is not much difference between my k-nn and weighted k-nn errors but it increases while k increases. Also while k is increasing the MAE value decreases.  I think choosing k between 20 and 35 is appropriate. The graphics are below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Absolute Error')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "k_range = [5, 20, 35, 50]\n",
    "\n",
    "plt.plot(k_range, all_error)\n",
    "plt.xlabel('Value of K for KNN')\n",
    "plt.ylabel('Mean Absolute Error')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Mean Absolute Error')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(k_range, w_all_error)\n",
    "plt.xlabel('Value of K for Weighted KNN')\n",
    "plt.ylabel('Mean Absolute Error')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think for my code, 30 for the k value is appropriate. Below, I have tried 30 as k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7056474056319337\n",
      "0.7057724618408973\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "weighted_errors = []\n",
    "\n",
    "test_model(30, similarity_matrix, final_pivot, pivot, errors, weighted_errors)\n",
    "print(calculate_MAE(errors))\n",
    "print(calculate_MAE(weighted_errors))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "[1] Pictures in the k-nn and weighted k-nn part is from : https://www.youtube.com/watch?v=h9gpufJFF-0&t=741s\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
